{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.evaluation import Evaluator, make_evaluation_predictions\n",
    "from lag_llama.gluon.estimator import LagLlamaEstimator\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(\"AAPL\", start=\"2010-01-01\", end=\"2023-12-31\")\n",
    "\n",
    "# Preproses data (contoh sederhana)\n",
    "train_data = data.iloc[:int(len(data)*0.7)]\n",
    "val_data = data.iloc[int(len(data)*0.7):int(len(data)*0.9)]\n",
    "test_data = data.iloc[int(len(data)*0.9):]\n",
    "\n",
    "\n",
    "# Buat dataset Gluonts\n",
    "train_ds = ListDataset([{\"start\": train_data.index[0], \"target\": train_data[\"Close\"]}], freq=\"D\")\n",
    "val_ds = ListDataset([{\"start\": val_data.index[0], \"target\": val_data[\"Close\"]}], freq=\"D\")\n",
    "test_ds = ListDataset([{\"start\": test_data.index[0], \"target\": test_data[\"Close\"]}], freq=\"D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': Period('2010-01-04', 'D'),\n",
       "  'target': array([ 7.643214,  7.656429,  7.534643, ..., 58.83    , 58.5925  ,\n",
       "         58.82    ], dtype=float32)}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_length = 60\n",
    "num_samples = 1060\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "ckpt = torch.load(\"./lag-llama-model/lag-llama.ckpt\", map_location=device) # Uses GPU since in this Colab we use a GPU.\n",
    "estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
    "\n",
    "rope_scaling_arguments = {\n",
    "    \"type\": \"linear\",\n",
    "    \"factor\": max(1.0, (context_length + prediction_length) / estimator_args[\"context_length\"]),\n",
    "}\n",
    "estimator = LagLlamaEstimator(\n",
    "    ckpt_path=\"./lag-llama-model/lag-llama.ckpt\",\n",
    "    prediction_length=prediction_length,\n",
    "    context_length=context_length, # Lag-Llama was trained with a context length of 32, but can work with any context length\n",
    "    # estimator args\n",
    "    input_size=estimator_args[\"input_size\"],\n",
    "    n_layer=estimator_args[\"n_layer\"],\n",
    "    n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
    "    n_head=estimator_args[\"n_head\"],\n",
    "    scaling=estimator_args[\"scaling\"],\n",
    "    time_feat=estimator_args[\"time_feat\"],\n",
    "    rope_scaling=rope_scaling_arguments if use_rope_scaling else None,\n",
    "    batch_size=1,\n",
    "    num_parallel_samples=100,\n",
    "    device=device,\n",
    ")\n",
    "lightning_module = estimator.create_lightning_module()\n",
    "transformation = estimator.create_transformation()\n",
    "predictor = estimator.create_predictor(transformation, lightning_module)\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=dataset,\n",
    "    predictor=predictor,\n",
    "    num_samples=num_samples\n",
    ")\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
